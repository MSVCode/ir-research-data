The argument for robot 'personhood'
It’s less about the damage we might do to robots, but the damage we might do with them

What are the rights of a robot? Does it have any? Should it? It's a question few of us have given much thought to, outside of a Friday night curled up in front of a science fiction movie. In fact, for many, the debate over the legal personhood of a robot probably isn't something they thought they'd ever need to question in their lifetime. 

And yet, that time seems to have come.

In January, a European parliamentary committee voted to consider new regulations that, among other things, could grant legal personhood to robots. The committee's draft report suggests ethical guidelines for the development of robots and artificial intelligence (AI), and the liability and obligations of the companies responsible. 

The suggestions are focused on ensuring that, as robots become more capable and autonomous, AI have rights and responsibilities too — and corporations be made accountable for the actions and decisions their machine beings make.

Giving robots the legal distinction of personhood is not so much meant to give them human rights, or claim they will one day be our peers. Rather, such regulations are more for our own sake — to define who bears responsibility for their actions and to prevent companies from sidestepping accountability when something goes wrong.

What is a robot?

We're not just talking about Siri, either. The use of AI is poised to grow exponentially over the next few decades, disrupting everything from white collar industries to the front lines of war. These machine beings won't be the same robots we're familiar with today; with each iteration and interaction, they will become more intelligent, sophisticated and intuitive. 

Slowly but surely, we will become more accustomed to their presence in our daily lives. And as the autonomy of robots and AI increases, it will be harder to consider them mere tools or objects. 

With robots poised to be our caretakers, our companions, our colleagues and our protectors, it's important to consider: What is a robot? And how should we relate to one?

At present, it's difficult to think far ahead enough to really consider what the personhood of a robot might entail. Sure, sci-fi is full of artificially intelligent beings that their human co-stars bond with, and that we, in the audience, empathize with. But Siri? Alexa? The Roomba? None of these popular commercial robots or AI come anywhere near human intelligence, let alone sentience. 

In the context of what's on the market today, the answer seems obvious: of course a robot does not deserve legal personhood. A robot is not a person. 

But, then again, neither are corporations, and they've been granted personhood too. 

When things go wrong

The premise is that corporations, distinct from the humans that own them or run them, have some of the legal rights and responsibilities of a human being, for instance, a corporation can enter into a contract, or be sued. 

Similarly, animal rights lawyers have been battling for over a decade now to have our intelligent animal counterparts – whales and chimpanzees – granted personhood status. And as of this month, there are even three rivers that now legally have the same rights as humans. 

The push for animal personhood has been an attempt to remedy human neglect, abuse, or violence. By giving something the status of a human, we give it a new sense of respect and dignity. Animals have long been hunted and kept within inhumane confines; the rivers that have been granted personhood have been so polluted that they are now too toxic to support life. Personhood is a means of protecting them, by ensuring them access to the law, which isn't the norm for most animals or bodies of water.

But while the precedent for seeking "electronic personhood" suggests an attempt at proceeding with caution, and compassion, into this new domain of artificial life, the argument for robot rights is less about the damage we might do to them, but more so, the damage we might do with them, and where responsibility lies when things go wrong.

More than just tools

This is a complex and tricky issue to unpack, because when we think of our own personhood, we think of the traits that make us inherently "human," such as instinct, emotion, and knowing the difference between right and wrong. In this respect, robots, by their very mechanical nature, feel distinctively non-human. 

But according to the law, a person is recognized as such, not because of their human-ness, but because rights and responsibilities are ascribed to them. 

If a self-driving car crashes into a crowd of people, the fact that it was driving itself doesn't free the corporation from responsibility. Similarly, if a companion robot caring for an elderly patient is neglectful, or a warbot goes on a rogue rampage, the autonomy of these machines does not negate the accountability of their creators and what they've programmed their creations to do, or not do. 

These are not mere tools, and for our own safety and security, we need to think of them as more than just possessions. Personhood doesn't mean that robots are the equivalent of people, but it does mean that they have certain rights and responsibilities — and that means now, and not off in some science fiction future, is when companies need to take accountability for the machines being created.